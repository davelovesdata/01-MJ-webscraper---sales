{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Marijuana Medical and Retail Sales Information\n",
    "\n",
    "### D.L. Martinez, 9/5/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this activity is to gather a list of all county marijuana sales files from the following public facing website:<br> \n",
    "https://www.colorado.gov/pacific/revenue/colorado-marijuana-sales-reports<br>\n",
    "\n",
    "A companion file for gathering state collected revenue information will also be generated.<br>\n",
    "\n",
    "Resources:<br>\n",
    "https://pythonspot.com/extract-links-from-webpage-beautifulsoup/<br>\n",
    "https://www.geeksforgeeks.org/downloading-files-web-using-python/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re     #regex\n",
    "import time   #for pausing execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#website pages to scrape\n",
    "page = \"https://www.colorado.gov/pacific/revenue/colorado-marijuana-sales-reports\"  #contains Colorado MJ business sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sales webpage\n",
    "resp = requests.get(page)\n",
    "\n",
    "#get the webpage content\n",
    "html = resp.content\n",
    "\n",
    "#make pretty with bs4\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#find all '<a>' tags (hyperlinks) \n",
    "urls = []\n",
    "for link in soup.findAll('a', attrs={'href': re.compile(\"PUBLISH.xlsx\")}):\n",
    "    urls.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first item is not necessary for my purposes so it is removed\n",
    "del(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve files and save to local directory\n",
    "for link in urls: \n",
    "        #use regex to split out the date as a filename - only digits are needed\n",
    "        filename = re.search(r'\\d+', link)\n",
    "        fileext = str('.xlsx')\n",
    "  \n",
    "        print(\"Downloading file:%s\"%filename) \n",
    "          \n",
    "        #create response object \n",
    "        r = requests.get(link, verify=False) \n",
    "          \n",
    "        #write data to local directory \n",
    "        with open(filename.group(0)+'_sales'+fileext, 'wb') as output:\n",
    "             output.write(r.content)\n",
    "        \n",
    "        print(\"%s downloaded!\\n\"%filename)\n",
    "        time.sleep(30)  #avoid overwhelming the server\n",
    "        \n",
    "print(\"All excel files downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
